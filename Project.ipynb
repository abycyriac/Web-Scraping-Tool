{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: This code should only be used as a reference and the responsibility of using this code lies solely on the user/users who is/ are using/executing it.\n",
    "\n",
    "This program scrapes Metacritics, IMDB and Rotten Tomatoes for movies genres. then save them to CSVs. The library used is BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "\n",
    "no_movies = 10 # You can change this number to change to number of the movies scarped. \n",
    "               # It can accept value from 0 to 100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Metacritics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url for Metacritics: https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You get three tries to make the url right! The right url is given in the markdown cell above.\n",
      "Enter url for Metacritics- https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc\n"
     ]
    }
   ],
   "source": [
    "# The url to be entered is given above\n",
    "print(\"You get three tries to make the url right! The right url is given in the markdown cell above.\")\n",
    "i = 0\n",
    "while i<3:\n",
    "    url = input('Enter url for Metacritics- ')\n",
    "    if url == \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc\": \n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        container = soup.find_all('td', class_ = 'clamp-summary-wrap')\n",
    "\n",
    "\n",
    "        movie_names = [] # list of first no_movies movies names\n",
    "        movie_links = [] # list of first no_movies movies names to scrape genres\n",
    "        movies = container[:no_movies] #here we get the top no_movies movies we want\n",
    "\n",
    "        # Scraping movie names\n",
    "        for movie in movies:\n",
    "            name = movie.find('h3').text\n",
    "            movie_names.append(name)\n",
    "\n",
    "        # Scraping individual movie links\n",
    "        for movie in movies:\n",
    "            tag = movie.find('a', class_ = 'title')\n",
    "            link = tag.get('href', None)\n",
    "            movie_links.append(link)\n",
    "\n",
    "        movie_genre = {}\n",
    "        final_raw_genres = []\n",
    "        genres=[]\n",
    "\n",
    "        # Scraping the genres of all the movies\n",
    "        for link in movie_links:\n",
    "            url = \"https://www.metacritic.com/\"+link\n",
    "            page = requests.get(url, headers = headers)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            genre_container = soup.find_all('div', class_ = 'genres')\n",
    "            genre_container = genre_container[:]\n",
    "            raw_genres = [span.text for span in genre_container]\n",
    "\n",
    "            for i in raw_genres:\n",
    "                temp = i.split(',')\n",
    "                temp1 = [k.replace(\"\\n\",\"\") for k in temp]\n",
    "                temp1[0] = temp1[0][9:]\n",
    "                for k in range(len(temp1)):\n",
    "                    temp1[k]=temp1[k].strip().lower()\n",
    "            final_raw_genres.append(temp1)\n",
    "\n",
    "\n",
    "        # Dictionary with movies name as keys and corresponding genres as the values\n",
    "        dict_movie_metacritics = {}\n",
    "        for movie, gen in zip(movie_names, final_raw_genres):\n",
    "            dict_movie_metacritics[movie] = gen\n",
    "\n",
    "        # Getting the movies with most number of genres\n",
    "        largest = 0\n",
    "        val = None\n",
    "        for i in dict_movie_metacritics.keys():\n",
    "            if largest<len(dict_movie_metacritics[i]):\n",
    "                largest = len(dict_movie_metacritics[i])\n",
    "                val = i\n",
    "\n",
    "        # Dataframa of genres with movie names as columns names\n",
    "        df = pd.DataFrame(columns = list(dict_movie_metacritics.keys()))\n",
    "        df[str(val)] = pd.Series(np.array(dict_movie_metacritics[val]))\n",
    "\n",
    "        for i in dict_movie_metacritics.keys():\n",
    "            df[str(i)] = pd.Series(np.array(dict_movie_metacritics[i]))\n",
    "\n",
    "        # Saving to CSV\n",
    "        df.to_csv('metacritics_genres.csv',index=False)\n",
    "        break\n",
    "        \n",
    "    if i<2:\n",
    "        if i ==1:\n",
    "            print(\"You have only one try left! try Again\")\n",
    "        else:\n",
    "            print(\"You have \",2-i,\" tries left! try Again\")\n",
    "    else:\n",
    "        print(\"You have exceeded your number of tries! Exiting! Goodbye!\")\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Citizen Kane': ['drama', 'mystery'], 'The Godfather': ['drama', 'thriller', 'crime'], 'Rear Window': ['mystery', 'thriller'], 'Casablanca': ['drama', 'romance', 'war'], 'Boyhood': ['drama'], 'Three Colors: Red': ['drama', 'mystery', 'romance'], 'Vertigo': ['mystery', 'thriller', 'romance'], 'Notorious': ['drama', 'thriller', 'romance', 'film-noir'], \"Singin' in the Rain\": ['comedy', 'romance', 'musical'], 'City Lights': ['drama', 'comedy', 'romance']}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(dict_movie_metacritics)\n",
    "except:\n",
    "    print(\"You didn't run the previous block of code correctly! Please run that code block correctly by providing the right url from the markdown cell above before running ths code block!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url for IMDB: https://www.imdb.com/chart/top/?ref_=nv_mv_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You get three tries to make the url right! The right url is given in the markdown cell above.\n",
      "Enter url for IMDB- https://www.imdb.com/chart/top/?ref_=nv_mv_250\n"
     ]
    }
   ],
   "source": [
    "# The url to be entered is given above\n",
    "print(\"You get three tries to make the url right! The right url is given in the markdown cell above.\")\n",
    "i = 0\n",
    "while i<3:\n",
    "    url = input('Enter url for IMDB- ')\n",
    "    if url == \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\":\n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        container = soup.find_all('td', class_ = 'titleColumn') \n",
    "\n",
    "        movie_names = [] # list of first no_movies movies names\n",
    "        movie_links = [] # list of first no_movies movies names to scrape genres\n",
    "        movies = container[:no_movies] #here we get the top 50 movies we want\n",
    "\n",
    "        # Scraping movie names\n",
    "        for movie in movies:\n",
    "            name = movie.find('a').text\n",
    "            movie_names.append(name)\n",
    "\n",
    "        # Scraping individual movie links    \n",
    "        for movie in movies:\n",
    "            tag = movie.find('a')\n",
    "            link = tag.get('href', None)\n",
    "            movie_links.append(link)\n",
    "\n",
    "        container_genre = {}\n",
    "        final_raw_genres = {}\n",
    "        genres_list=[]\n",
    "        container = None\n",
    "\n",
    "        # Scraping the genres of all the movies\n",
    "        for link, movie in zip(movie_links, movie_names):\n",
    "            url = \"https://www.imdb.com/\"+link\n",
    "            page = requests.get(url, headers = headers)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            container = soup.find_all('div', class_= \"see-more inline canwrap\")\n",
    "            final_raw_genres[movie] = container[1].find_all('a')\n",
    "\n",
    "        # Dictionary with movies name as keys and corresponding genres as the values\n",
    "        dict_movie_imdb = {}\n",
    "        for i in final_raw_genres.keys():\n",
    "            arr_genres = []\n",
    "            for j in final_raw_genres[i]:\n",
    "                arr_genres.append(j.text.strip().lower())\n",
    "            dict_movie_imdb[i]=arr_genres\n",
    "\n",
    "\n",
    "        # Getting the movies with most number of genres\n",
    "        largest = 0\n",
    "        val = None\n",
    "        for i in dict_movie_imdb.keys():\n",
    "            if largest<len(dict_movie_imdb[i]):\n",
    "                largest = len(dict_movie_imdb[i])\n",
    "                val = i\n",
    "        # Dataframa of genres with movie names as columns names\n",
    "        df = pd.DataFrame(columns = list(dict_movie_imdb.keys()))\n",
    "        df[str(val)] = pd.Series(np.array(dict_movie_imdb[val]))\n",
    "\n",
    "        for i in dict_movie_imdb.keys():\n",
    "            df[str(i)] = pd.Series(np.array(dict_movie_imdb[i]))\n",
    "\n",
    "        # Saving to CSV\n",
    "        df.to_csv('imdb_genres.csv',index=False)\n",
    "        break\n",
    "        \n",
    "    if i<2:\n",
    "        if i ==1:\n",
    "            print(\"You have only one try left! try Again\")\n",
    "        else:\n",
    "            print(\"You have \",2-i,\" tries left! try Again\")\n",
    "    else:\n",
    "        print(\"You have exceeded your number of tries! Exiting! Goodbye!\")\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The Shawshank Redemption': ['drama'], 'The Godfather': ['crime', 'drama'], 'The Godfather: Part II': ['crime', 'drama'], 'The Dark Knight': ['action', 'crime', 'drama', 'thriller'], '12 Angry Men': ['crime', 'drama'], \"Schindler's List\": ['biography', 'drama', 'history'], 'The Lord of the Rings: The Return of the King': ['action', 'adventure', 'drama', 'fantasy'], 'Pulp Fiction': ['crime', 'drama'], 'The Good, the Bad and the Ugly': ['western'], 'The Lord of the Rings: The Fellowship of the Ring': ['action', 'adventure', 'drama', 'fantasy']}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(dict_movie_imdb)\n",
    "except:\n",
    "    print(\"You didn't run the previous block of code correctly! Please run that code block correctly by providing the right url from the markdown cell above before running ths code block!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Rotten Tomatoes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url for Rotten Tomatoes: https://www.rottentomatoes.com/top/bestofrt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You get three tries to make the url right! The right url is given in the markdown cell above.\n",
      "Enter the url for Rotten Tomatoes- https://www.rottentomatoes.com/top/bestofrt/\n"
     ]
    }
   ],
   "source": [
    "# The url to be entered is given above\n",
    "print(\"You get three tries to make the url right! The right url is given in the markdown cell above.\")\n",
    "i = 0\n",
    "while i<3:\n",
    "    url = input('Enter the url for Rotten Tomatoes- ')\n",
    "    if url == \"https://www.rottentomatoes.com/top/bestofrt/\": \n",
    "        page = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        container = soup.find_all('a', class_=\"unstyled articleLink\")\n",
    "        container = container[43:-2]\n",
    "\n",
    "        movie_names = [] # list of first no_movies movies names\n",
    "        movie_links = [] # list of first no_movies movies names to scrape genres\n",
    "        movies = container[:no_movies] #here we get the top 50 movies we want\n",
    "\n",
    "        # Scraping movie names\n",
    "        for movie in movies:\n",
    "            movie=str(movie)\n",
    "            start = [x for x, v in enumerate(movie) if v == '>'][0]\n",
    "            end = [x for x, v in enumerate(movie) if v == '<'][1]\n",
    "            movie_names.append(movie[start+2:end].strip())\n",
    "\n",
    "        # Scraping individual movie links\n",
    "        for movie in movies:\n",
    "            link = movie.get('href', None)\n",
    "            movie_links.append(link)\n",
    "\n",
    "        movie_genre = {}\n",
    "        final_raw_genres = []\n",
    "        genres=[]\n",
    "        # Scraping the genres of all the movies\n",
    "        for link in movie_links:\n",
    "            url = \"https://www.rottentomatoes.com\"+link\n",
    "            page = requests.get(url, headers = headers)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "            genre_container = soup.find_all('div', class_=\"meta-value genre\")\n",
    "            raw_genres = [span.text for span in genre_container]\n",
    "\n",
    "            temp_genre = []\n",
    "            for i in raw_genres:\n",
    "                temp= i.split(',')\n",
    "            for i in temp:\n",
    "                temp_genre.append(i.strip())\n",
    "            final_raw_genres.append(temp_genre)\n",
    "\n",
    "        # Dictionary with movies name as keys and corresponding genres as the values\n",
    "        dict_movie_rotten_tomatoes = {}\n",
    "        for movie, gen in zip(movie_names, final_raw_genres):\n",
    "            dict_movie_rotten_tomatoes[movie] = gen\n",
    "\n",
    "        # Getting the movies with most number of genres\n",
    "        largest = 0\n",
    "        val = None\n",
    "        for i in dict_movie_rotten_tomatoes.keys():\n",
    "            if largest<len(dict_movie_rotten_tomatoes[i]):\n",
    "                largest = len(dict_movie_rotten_tomatoes[i])\n",
    "                val = i\n",
    "\n",
    "        # Dataframa of genres with movie names as columns names\n",
    "        df = pd.DataFrame(columns = list(dict_movie_rotten_tomatoes.keys()))\n",
    "        df[str(val)] = pd.Series(np.array(dict_movie_rotten_tomatoes[val]))\n",
    "\n",
    "        for i in dict_movie_rotten_tomatoes.keys():\n",
    "            df[str(i)] = pd.Series(np.array(dict_movie_rotten_tomatoes[i]))\n",
    "\n",
    "        # Saving to CSV\n",
    "        df.to_csv('rotten_tomatoes_genres.csv',index=False)\n",
    "        break\n",
    "\n",
    "\n",
    "    if i<2:\n",
    "        if i ==1:\n",
    "            print(\"You have only one try left! try Again\")\n",
    "        else:\n",
    "            print(\"You have \",2-i,\" tries left! try Again\")\n",
    "    else:\n",
    "        print(\"You have exceeded your number of tries! Exiting! Goodbye!\")\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Black Panther (2018)': ['fantasy', 'adventure', 'action'], 'Avengers: Endgame (2019)': ['fantasy', 'adventure', 'sci fi', 'action'], 'Us (2019)': ['horror', 'mystery and thriller'], 'Toy Story 4 (2019)': ['fantasy', 'kids and family', 'animation', 'adventure', 'comedy'], 'Lady Bird (2017)': ['drama', 'comedy'], 'Citizen Kane (1941)': ['drama'], 'Mission: Impossible - Fallout (2018)': ['adventure', 'mystery and thriller', 'action'], 'The Wizard of Oz (1939)': ['fantasy', 'kids and family', 'musical'], 'BlacKkKlansman (2018)': ['drama', 'comedy', 'crime'], 'Get Out (2017)': ['horror', 'mystery and thriller', 'comedy']}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(dict_movie_rotten_tomatoes)\n",
    "except:\n",
    "    print(\"You didn't run the previous block of code correctly! Please run that code block correctly by providing the right url from the markdown cell above before running ths code block!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
